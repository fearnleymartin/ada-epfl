{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Data-Wrangling-with-Pandas\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Wrangling with Pandas</a></div><div class=\"lev2\"><a href=\"#Date/Time-data-handling\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Date/Time data handling</a></div><div class=\"lev2\"><a href=\"#Merging-and-joining-DataFrame-objects\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Merging and joining DataFrame objects</a></div><div class=\"lev2\"><a href=\"#Concatenation\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Concatenation</a></div><div class=\"lev2\"><a href=\"#Exercise\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Exercise</a></div><div class=\"lev2\"><a href=\"#Reshaping-DataFrame-objects\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Reshaping DataFrame objects</a></div><div class=\"lev2\"><a href=\"#Pivoting\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Pivoting</a></div><div class=\"lev2\"><a href=\"#Data-transformation\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Data transformation</a></div><div class=\"lev3\"><a href=\"#Dealing-with-duplicates\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Dealing with duplicates</a></div><div class=\"lev3\"><a href=\"#Value-replacement\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>Value replacement</a></div><div class=\"lev3\"><a href=\"#Inidcator-variables\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>Inidcator variables</a></div><div class=\"lev2\"><a href=\"#Categorical-Data\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Categorical Data</a></div><div class=\"lev3\"><a href=\"#Discretization\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Discretization</a></div><div class=\"lev3\"><a href=\"#Permutation-and-sampling\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Permutation and sampling</a></div><div class=\"lev2\"><a href=\"#Data-aggregation-and-GroupBy-operations\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Data aggregation and GroupBy operations</a></div><div class=\"lev3\"><a href=\"#Apply\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>Apply</a></div><div class=\"lev2\"><a href=\"#Exercise\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Exercise</a></div><div class=\"lev2\"><a href=\"#References\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>References</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Pandas\n",
    "\n",
    "Now that we have been exposed to the basic functionality of Pandas, lets explore some more advanced features that will be useful when addressing more complex data management tasks.\n",
    "\n",
    "As most statisticians/data analysts will admit, often the lion's share of the time spent implementing an analysis is devoted to preparing the data itself, rather than to coding or running a particular model that uses the data. This is where Pandas and  Python's standard library are beneficial, providing high-level, flexible, and efficient tools for manipulating your data as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fearnley\\Anaconda2\\envs\\py35\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/Time data handling\n",
    "\n",
    "Date and time data are inherently problematic. There are an unequal number of days in every month, an unequal number of days in a year (due to leap years), and time zones that vary over space. Yet information about time is essential in many analyses, particularly in the case of time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datetime` built-in library handles temporal information down to the nanosecond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now.weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `datetime` there are simpler objects for date and time information only, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time(3, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date(1970, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a custom data type for dates and times is convenient because we can perform operations on them easily. For example, we may want to calculate the difference between two times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_age = now - datetime(1994, 8, 14)\n",
    "my_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(my_age))\n",
    "my_age.days/365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will manipulate data collected from ocean-going vessels on the eastern seaboard. Vessel operations are monitored using the Automatic Identification System (AIS), a safety at sea navigation technology which vessels are required to maintain and that uses transponders to transmit very high frequency (VHF) radio signals containing static information including ship name, call sign, and country of origin, as well as dynamic information unique to a particular voyage such as vessel location, heading, and speed. \n",
    "\n",
    "The International Maritime Organizationâ€™s (IMO) International Convention for the Safety of Life at Sea requires functioning AIS capabilities on all vessels 300 gross tons or greater and the US Coast Guard requires AIS on nearly all vessels sailing in U.S. waters. The Coast Guard has established a national network of AIS receivers that provides coverage of nearly all U.S. waters. AIS signals are transmitted several times each minute and the network is capable of handling thousands of reports per minute and updates as often as every two seconds. Therefore, a typical voyage in our study might include the transmission of hundreds or thousands of AIS encoded signals. This provides a rich source of spatial data that includes both spatial and temporal information.\n",
    "\n",
    "For our purposes, we will use summarized data that describes the transit of a given vessel through a particular administrative area. The data includes the start and end time of the transit segment, as well as information about the speed of the vessel, how far it travelled, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments = pd.read_csv(\"Data/AIS/transit_segments.csv\")\n",
    "segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we might be interested in the distribution of transit lengths, so we can plot them as a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.seg_length.hist(bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though most of the transits appear to be short, there are a few longer distances that make the plot difficult to read. This is where a transformation is useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.seg_length.apply(np.log).hist(bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although there are date/time fields in the dataset, they are not in any specialized format, such as `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first order of business will be to convert these data to `datetime`. The `strptime` method parses a string representation of a date and/or time field, according to the expected format of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime.strptime(segments.st_time.ix[0], '%m/%d/%y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dateutil` package includes a parser that attempts to detect the format of the date strings, and convert them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse(segments.st_time.ix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert all the dates in a particular column by using the `apply` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.apply(lambda d: datetime.strptime(d, '%m/%d/%y %H:%M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience, Pandas has a `to_datetime` method that will parse and convert an entire Series of formatted strings into `datetime` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(segments.st_time[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also has a custom NA value for missing datetime objects, `NaT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_datetime([None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if `to_datetime()` has problems parsing any particular date/time format, you can pass the spec in using the `format=` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_*` functions now have an optional `parse_dates` argument that try to convert any columns passed to it into `datetime` format upon import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments = pd.read_csv(\"Data/AIS/transit_segments.csv\", parse_dates=['st_time', 'end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the `datetime` type have an **accessor** to easily extract properties of the data type. This will return a `Series`, with the same row index as the `DataFrame`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.dt.month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.dt.hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to easily filter rows by particular temporal attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments[segments.st_time.dt.month==2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, time zone information can be applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.dt.tz_localize('UTC').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.st_time.dt.tz_localize('UTC').dt.tz_convert('US/Eastern').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and joining DataFrame objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the vessel transit information as we need it, we may want a little more information regarding the vessels themselves. In the `data/AIS` folder there is a second table that contains information about each of the ships that traveled the segments in the `segments` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels = pd.read_csv(\"Data/AIS/vessel_information.csv\", index_col='mmsi')\n",
    "vessels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[v for v in vessels.type.unique() if v.find('/')==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge, however, is that several ships have travelled multiple segments, so there is not a one-to-one relationship between the rows of the two tables. The table of vessel information has a *one-to-many* relationship with the segments.\n",
    "\n",
    "In Pandas, we can combine tables according to the value of one or more *keys* that are used to identify rows, much like an index. Using a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(dict(id=range(4), age=np.random.randint(18, 31, size=4)))\n",
    "df2 = pd.DataFrame(dict(id=list(range(3))+list(range(3)), \n",
    "                        score=np.random.random(size=6)))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that without any information about which column to use as a key, Pandas did the right thing and used the `id` column in both tables. Unless specified otherwise, `merge` will used any common column names as keys for merging the tables. \n",
    "\n",
    "Notice also that `id=3` from `df1` was omitted from the merged table. This is because, by default, `merge` performs an **inner join** on the tables, meaning that the merged table represents an intersection of the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **outer join** above yields the union of the two tables, so all rows are represented, with missing values inserted as appropriate. One can also perform **right** and **left** joins to include all rows of the right or left table (*i.e.* first or second argument to `merge`), but not necessarily the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the two datasets that we wish to merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that there is a `mmsi` value (a vessel identifier) in each table, but it is used as an index for the `vessels` table. In this case, we have to specify to join on the index for this table, and on the `mmsi` column for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the default inner join is suitable; we are not interested in observations from either table that do not have corresponding entries in the other. \n",
    "\n",
    "Notice that `mmsi` field that was an index on the `vessels` table is no longer an index on the merged table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used the `merge` function to perform the merge; we could also have used the `merge` *method* for either of the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.merge(segments, left_index=True, right_on='mmsi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, there will be fields with the same in both tables that we do not wish to use to join the tables; they may contain different information, despite having the same name. In this case, Pandas will by default append suffixes `_x` and `_y` to the columns to uniquely identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments['type'] = 'foo'\n",
    "pd.merge(vessels, segments, left_index=True, right_on='mmsi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior can be overridden by specifying a `suffixes` argument, containing a list of the suffixes to be used for the columns of the left and right columns, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "\n",
    "A common data manipulation is appending rows or columns to a dataset that already conform to the dimensions of the exsiting rows or colums, respectively. In NumPy, this is done either with `concatenate` or the convenience \"functions\" `c_` and `r_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate([np.random.random(5), np.random.random(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.r_[np.random.random(5), np.random.random(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.c_[np.random.random(5), np.random.random(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that `c_` and `r_` are not really functions at all, since it is performing some sort of indexing operation, rather than being called. They are actually *class instances*, but they are here behaving mostly like functions. Don't think about this too hard; just know that they are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is also called *binding* or *stacking*.\n",
    "\n",
    "With Pandas' indexed data structures, there are additional considerations as the overlap in index values between two data structures affects how they are concatenate.\n",
    "\n",
    "Lets import two microbiome datasets, each consisting of counts of microorganiams from a particular patient. We will use the first column of each dataset as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1 = pd.read_excel('Data/microbiome/MID1.xls', 'Sheet 1', index_col=0, header=None)\n",
    "mb2 = pd.read_excel('Data/microbiome/MID2.xls', 'Sheet 1', index_col=0, header=None)\n",
    "mb1.shape, mb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the index and columns meaningful labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.columns = mb2.columns = ['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.index.name = mb2.index.name = 'Taxon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of these data is the unique biological classification of each organism, beginning with *domain*, *phylum*, *class*, and for some organisms, going all the way down to the genus level.\n",
    "\n",
    "![classification](http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Biological_classification_L_Pengo_vflip.svg/150px-Biological_classification_L_Pengo_vflip.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.index[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we concatenate along `axis=0` (the default), we will obtain another data frame with the the rows concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the index is no longer unique, due to overlap between the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating along `axis=1` will concatenate column-wise, but respecting the indices of the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are only interested in taxa that are included in both DataFrames, we can specify a `join=inner` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=1, join='inner').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to use the second table to *fill values* absent from the first table, we could use `combine_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.combine_first(mb2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a hierarchical index based on keys identifying the original tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], keys=['patient1', 'patient2']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], keys=['patient1', 'patient2']).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can pass keys to the concatenation by supplying the DataFrames (or Series) as a dict, resulting in a \"wide\" format table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(dict(patient1=mb1, patient2=mb2), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want `concat` to work like `numpy.concatanate`, you may provide the `ignore_index=True` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In the *data/microbiome* subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10th file that describes the content of each. Write code that imports each of the data spreadsheets and combines them into a single `DataFrame`, adding the identifying information from the metadata spreadsheet as columns in the combined `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Answer*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SAMPLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICROBIOME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera</th>\n",
       "      <td>7</td>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus</th>\n",
       "      <td>2</td>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus</th>\n",
       "      <td>3</td>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum</th>\n",
       "      <td>3</td>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella</th>\n",
       "      <td>7</td>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    COUNT BARCODE  \\\n",
       "MICROBIOME                                                          \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...      7    MID1   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...      2    MID1   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobal...      3    MID1   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoprot...      3    MID1   \n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Metha...      7    MID1   \n",
       "\n",
       "                                                                 GROUP SAMPLE  \n",
       "MICROBIOME                                                                     \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  EXTRACTION CONTROL    NaN  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  EXTRACTION CONTROL    NaN  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobal...  EXTRACTION CONTROL    NaN  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoprot...  EXTRACTION CONTROL    NaN  \n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Metha...  EXTRACTION CONTROL    NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_columns(data, metadata, i=0):\n",
    "    \"\"\" Add metadata to dataset i and name columns\"\"\"\n",
    "    data['BARCODE']=metadata.loc[i,'BARCODE']\n",
    "    data['GROUP']=metadata.loc[i,'GROUP']\n",
    "    data['SAMPLE']=metadata.loc[i,'SAMPLE']\n",
    "    data.columns = ['COUNT','BARCODE', 'GROUP', 'SAMPLE',]\n",
    "\n",
    "# Read metadata\n",
    "metadata = pd.read_excel('data/microbiome/metadata.xls', header=0)\n",
    "\n",
    "# Read and process dataset 1\n",
    "data = pd.read_excel('data/microbiome/MID1.xls', index_col=0, header=None)\n",
    "add_columns(data, metadata)  \n",
    "\n",
    "# Loop through other data sets and concatenate them with dataset 1\n",
    "for i in range(1,9):\n",
    "    data_to_concat = pd.read_excel('data/microbiome/MID'+str(i)+'.xls', index_col=0, header=None)\n",
    "    add_columns(data_to_concat, metadata,i)\n",
    "    data = pd.concat([data, data_to_concat], axis=0)\n",
    "\n",
    "# Name index   \n",
    "data.index.name = 'MICROBIOME'\n",
    "data.head()\n",
    "\n",
    "# Optional code to swith to wide format (columns grouped by barcode)\n",
    "# data=data.pivot(data.index,'BARCODE')\n",
    "# data.swaplevel(0,1,axis=1).sort_index(axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping DataFrame objects\n",
    "\n",
    "In the context of a single DataFrame, we are often interested in re-arranging the layout of our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is from Table 6.9 of [Statistical Methods for the Analysis of Repeated Measurements](http://www.amazon.com/Statistical-Methods-Analysis-Repeated-Measurements/dp/0387953701) by Charles S. Davis, pp. 161-163 (Springer, 2002). These data are from a multicenter, randomized controlled trial of botulinum toxin type B (BotB) in patients with cervical dystonia from nine U.S. sites.\n",
    "\n",
    "* Randomized to placebo (N=36), 5000 units of BotB (N=36), 10,000 units of BotB (N=37)\n",
    "* Response variable: total score on Toronto Western Spasmodic Torticollis Rating Scale (TWSTRS), measuring severity, pain, and disability of cervical dystonia (high scores mean more impairment)\n",
    "* TWSTRS measured at baseline (week 0) and weeks 2, 4, 8, 12, 16 after treatment began"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia = pd.read_csv(\"Data/cdystonia.csv\", index_col=None)\n",
    "cdystonia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes repeated measurements of the same individuals (longitudinal data). Its possible to present such information in (at least) two ways: showing each repeated measurement in their own row, or in multiple columns representing multiple measurements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack` method rotates the data frame so that columns are represented in rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked = cdystonia.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement this, `unstack` pivots from rows back to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked.unstack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, it makes sense to create a hierarchical index based on the patient and observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia2 = cdystonia.set_index(['patient','obs'])\n",
    "cdystonia2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia2.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to transform this data so that repeated measurements are in columns, we can `unstack` the `twstrs` measurements according to `obs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twstrs_wide = cdystonia2['twstrs'].unstack('obs')\n",
    "twstrs_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_wide = (cdystonia[['patient','site','id','treat','age','sex']]\n",
    "                  .drop_duplicates()\n",
    "                  .merge(twstrs_wide, right_index=True, left_on='patient', how='inner')\n",
    "                  .head())\n",
    "cdystonia_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly cleaner way of doing this is to set the patient-level information as an index before unstacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(cdystonia.set_index(['patient','site','id','treat','age','sex','week'])['twstrs']\n",
    "     .unstack('week').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our \"wide\" format back to long, we can use the `melt` function, appropriately parameterized. This function is useful for `DataFrame`s where one\n",
    "or more columns are identifier variables (`id_vars`), with the remaining columns being measured variables (`value_vars`). The measured variables are \"unpivoted\" to\n",
    "the row axis, leaving just two non-identifier columns, a *variable* and its corresponding *value*, which can both be renamed using optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.melt(cdystonia_wide, id_vars=['patient','site','id','treat','age','sex'], \n",
    "        var_name='obs', value_name='twsters').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates the two formats for longitudinal data: **long** and **wide** formats. Its typically better to store data in long format because additional data can be included as additional rows in the database, while wide format requires that the entire database schema be altered by adding columns to every row as data are collected.\n",
    "\n",
    "The preferable format for analysis depends entirely on what is planned for the data, so it is imporant to be able to move easily between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "The `pivot` method allows a DataFrame to be transformed easily between long and wide formats in the same way as a pivot table is created in a spreadsheet. It takes three arguments: `index`, `columns` and `values`, corresponding to the DataFrame index (the row headers), columns and cell values, respectively.\n",
    "\n",
    "For example, we may want the `twstrs` variable (the response variable) in wide format according to patient, as we saw with the unstacking method above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.pivot(index='patient', columns='obs', values='twstrs').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we omit the `values` argument, we get a `DataFrame` with hierarchical columns, just as when we applied `unstack` to the hierarchically-indexed table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.pivot('patient', 'obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related method, `pivot_table`, creates a spreadsheet-like table with a hierarchical index, and allows the values of the table to be populated using an arbitrary aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.pivot_table(index=['site', 'treat'], columns='week', values='twstrs', \n",
    "                      aggfunc=max).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple cross-tabulation of group frequencies, the `crosstab` function (not a method) aggregates counts of data according to factors in rows and columns. The factors may be hierarchical if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdystonia.sex, cdystonia.site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "\n",
    "There are a slew of additional operations for DataFrames that we would collectively refer to as \"transformations\" which include tasks such as removing duplicate values, replacing values, and grouping values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicates\n",
    "\n",
    "We can easily identify and remove duplicate values from `DataFrame` objects. For example, say we want to removed ships from our `vessels` dataset that have the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.duplicated(subset='names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vessels.drop_duplicates(['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value replacement\n",
    "\n",
    "Frequently, we get data columns that are encoded as strings that we wish to represent numerically for the purposes of including it in a quantitative analysis. For example, consider the treatment variable in the cervical dystonia dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logical way to specify these numerically is to change them to integer values, perhaps using \"Placebo\" as a baseline value. If we create a dict with the original values as keys and the replacements as values, we can pass it to the `map` method to implement the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treatment_map = {'Placebo': 0, '5000U': 1, '10000U': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia['treatment'] = cdystonia.treat.map(treatment_map)\n",
    "cdystonia.treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, if we simply want to replace particular values in a `Series` or `DataFrame`, we can use the `replace` method. \n",
    "\n",
    "An example where replacement is useful is dealing with zeros in certain transformations. For example, if we try to take the log of a set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = pd.Series([float(i)**10 for i in range(10)])\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such situations, we can replace the zero with a value so small that it makes no difference to the ensuing analysis. We can do this with `replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = vals.replace(0, 1e-6)\n",
    "np.log(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform the same replacement that we used `map` for with `replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia2.treat.replace({'Placebo': 0, '5000U': 1, '10000U': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inidcator variables\n",
    "\n",
    "For some statistical analyses (*e.g.* regression models or analyses of variance), categorical or group variables need to be converted into columns of indicators--zeros and ones--to create a so-called **design matrix**. The Pandas function `get_dummies` (indicator variables are also known as *dummy variables*) makes this transformation straightforward.\n",
    "\n",
    "Let's consider the DataFrame containing the ships corresponding to the transit segments on the eastern seaboard. The `type` variable denotes the class of vessel; we can create a matrix of indicators for this. For simplicity, lets filter out the 5 most common types of ships:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5 = vessels.type.isin(vessels.type.value_counts().index[:5])\n",
    "top5.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessels5 = vessels[top5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(vessels5.type).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data\n",
    "\n",
    "Pandas provides a convenient `dtype` for reprsenting categorical (factor) data, called `category`. \n",
    "\n",
    "For example, the `treat` column in the cervical dystonia dataset represents three treatment levels in a clinical trial, and is imported by default as an `object` type, since it is a mixture of string characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this to a `category` type either by the `Categorical` constructor, or casting the column using `astype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Categorical(cdystonia.treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia['treat'] = cdystonia.treat.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the Categorical type represents an unordered categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, an ordering can be imposed. The order is lexical by default, but will assume the order of the listed categories to be the desired order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.cat.categories = ['Placebo', '5000U', '10000U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.cat.as_ordered().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important difference between the `category` type and the `object` type is that `category` is represented by an underlying array of integers, which is then mapped to character labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.treat.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these are 8-bit integers, which are essentially single bytes of data, making memory usage lower.\n",
    "\n",
    "There is also a performance benefit. Consider an operation such as calculating the total segment lengths for each ship in the `segments` table (this is also a preview of pandas' `groupby` operation!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time segments.groupby(segments.name).seg_length.sum().sort_values(ascending=False, inplace=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments['name'] = segments.name.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time segments.groupby(segments.name).seg_length.sum().sort_values(ascending=False, inplace=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we get a considerable speedup simply by using the appropriate `dtype` for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization\n",
    "\n",
    "Pandas' `cut` function can be used to group continuous or countable data in to bins. Discretization is generally a very **bad idea** for statistical analysis, so use this function responsibly!\n",
    "\n",
    "Lets say we want to bin the ages of the cervical dystonia patients into a smaller number of groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform these data into decades, beginnnig with individuals in their 20's and ending with those in their 80's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(cdystonia.age, [20,30,40,50,60,70,80,90])[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parentheses indicate an open interval, meaning that the interval includes values up to but *not including* the endpoint, whereas the square bracket is a closed interval, where the endpoint is included in the interval. We can switch the closure to the left side by setting the `right` flag to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(cdystonia.age, [20,30,40,50,60,70,80,90], right=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data are now **ordinal**, rather than numeric, we can give them labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(cdystonia.age, [20,40,60,80,90], labels=['young','middle-aged','old','really old'])[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related function `qcut` uses empirical quantiles to divide the data. If, for example, we want the quartiles -- (0-25%], (25-50%], (50-70%], (75-100%] -- we can just specify 4 intervals, which will be equally-spaced by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.qcut(cdystonia.age, 4)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can specify custom quantiles to act as cut points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantiles = pd.qcut(segments.seg_length, [0, 0.01, 0.05, 0.95, 0.99, 1])\n",
    "quantiles[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can easily combine discretiztion with the generation of indicator variables shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(quantiles).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation and sampling\n",
    "\n",
    "For some data analysis tasks, such as simulation, we need to be able to randomly reorder our data, or draw random values from it. Calling NumPy's `permutation` function with the length of the sequence you want to permute generates an array with a permuted sequence of integers, which can be used to re-order the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_order = np.random.permutation(len(segments))\n",
    "new_order[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sequence as an argument to the `take` method results in a reordered DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.take(new_order).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this ordering with the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random sampling, `DataFrame` and `Series` objects have a `sample` method that can be used to draw samples, with or without replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vessels.sample(n=10, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation and GroupBy operations\n",
    "\n",
    "One of the most powerful features of Pandas is its **GroupBy** functionality. On occasion we may want to perform operations on *groups* of observations within a dataset. For exmaple:\n",
    "\n",
    "* **aggregation**, such as computing the sum of mean of each group, which involves applying a function to each group and returning the aggregated results\n",
    "* **slicing** the DataFrame into groups and then doing something with the resulting slices (*e.g.* plotting)\n",
    "* group-wise **transformation**, such as standardization/normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped = cdystonia.groupby(cdystonia.patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *grouped* dataset is hard to visualize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the grouping is only an intermediate step; for example, we may want to **iterate** over each of the patient groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for patient, group in cdystonia_grouped:\n",
    "    print('patient', patient)\n",
    "    print('group', group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common data analysis procedure is the **split-apply-combine** operation, which groups subsets of data together, applies a function to each of the groups, then recombines them into a new data table.\n",
    "\n",
    "For example, we may want to aggregate our data with with some function.\n",
    "\n",
    "![split-apply-combine](http://f.cl.ly/items/0s0Z252j0X0c3k3P1M47/Screen%20Shot%202013-06-02%20at%203.04.04%20PM.png)\n",
    "\n",
    "<div align=\"right\">*(figure taken from \"Python for Data Analysis\", p.251)*</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate in Pandas using the `aggregate` (or `agg`, for short) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped.agg(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `treat` and `sex` variables are not included in the aggregation. Since it does not make sense to aggregate non-string variables, these columns are simply ignored by the method.\n",
    "\n",
    "Some aggregation functions are so common that Pandas has a convenience method for them, such as `mean`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped.mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_prefix` and `add_suffix` methods can be used to give the columns of the resulting table labels that reflect the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped.mean().add_suffix('_mean').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The median of the `twstrs` variable\n",
    "cdystonia_grouped['twstrs'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish, we can easily aggregate according to multiple keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia.groupby(['week','site']).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we can **transform** the data, using a function of our choice with the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize = lambda x: (x - x.mean())/x.std()\n",
    "\n",
    "cdystonia_grouped.transform(normalize).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to do column selection within `groupby` operations, if we are only interested split-apply-combine operations on a subset of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped['twstrs'].mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This gives the same result as a DataFrame\n",
    "cdystonia_grouped[['twstrs']].mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you simply want to divide your DataFrame into chunks for later use, its easy to convert them into a dict so that they can be easily indexed out as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = dict(list(cdystonia_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `groupby` groups by row, but we can specify the `axis` argument to change this. For example, we can group our columns by `dtype` this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_by_type = cdystonia.groupby(cdystonia.dtypes, axis=1)\n",
    "{g:grouped_by_type.get_group(g) for g in grouped_by_type.groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also possible to group by one or more levels of a hierarchical index. Recall `cdystonia2`, which we created with a hierarchical index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdystonia2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia2.groupby(level='obs', axis=0)['twstrs'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "We can generalize the split-apply-combine methodology by using `apply` function. This allows us to invoke any function we wish on a grouped dataset and recombine them into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a DataFrame and a column name, sorts by the column, and takes the `n` largest values of that column. We can use this with `apply` to return the largest values from every group in a DataFrame in a single call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top(df, column, n=5):\n",
    "    return df.sort_values(by=column, ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this in action, consider the vessel transit segments dataset (which we merged with the vessel information to yield `segments_merged`). Say we wanted to return the 3 longest segments travelled by each ship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top3segments = segments_merged.groupby('mmsi').apply(top, column='seg_length', n=3)[['names', 'seg_length']]\n",
    "top3segments.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that additional arguments for the applied function can be passed via `apply` after the function name. It assumes that the DataFrame is the first argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the microbiome data sets that we used previously for the concatenation example. Suppose that we wish to aggregate the data at a higher biological classification than genus. For example, we can identify samples down to *class*, which is the 3rd level of organization in each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.index[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the string methods `split` and `join` we can create an index that just uses the first three classifications: domain, phylum and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_index = mb1.index.map(lambda x: ' '.join(x.split(' ')[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_class = mb1.copy()\n",
    "mb_class.index = class_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since there are multiple taxonomic units with the same class, our index is no longer unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-establish a unique index by summing all rows with the same class, using `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_class.groupby(level=0).sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Load the dataset in `titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename='Data/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Women and children first?\n",
    "\n",
    "1. Describe each attribute, both with basic statistics and plots. State clearly your assumptions and discuss your findings.\n",
    "2. Use the `groupby` method to calculate the proportion of passengers that survived by sex.\n",
    "3. Calculate the same proportion, but by class and sex.\n",
    "4. Create age categories: children (under 14 years), adolescents (14-20), adult (21-64), and senior(65+), and calculate survival proportions by age category, class and sex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What we obviously need to do first, is to import the data from the excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_excel ('Data/titanic.xls')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to get some quick insights from the data with count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1309\n",
       "survived     1309\n",
       "name         1309\n",
       "sex          1309\n",
       "age          1046\n",
       "sibsp        1309\n",
       "parch        1309\n",
       "ticket       1309\n",
       "fare         1308\n",
       "cabin         295\n",
       "embarked     1307\n",
       "boat          486\n",
       "body          121\n",
       "home.dest     745\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling count gives us some quick insights: there are 1309 entries in the table. We are missing quick a few entries for age and cabin. We are missing one entry for fare. Boats and bodys are missing a lot of values, but these aren't applicable to all passangers. home.dest is also missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check no names are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.name.isnull().values.ravel().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to know about this data, is how many people survived (expressed in percentage of all the passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "died        809\n",
       "survived    500\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surv = titanic.survived.replace (0, 'died').replace (1, 'survived').value_counts ()\n",
    "surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "died        62.0\n",
       "survived    38.0\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percentages\n",
    "round(100. * surv / len(titanic.survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows us that less than half of the people survived that Titanic journey. That's actually sad.\n",
    "\n",
    "As the name doesn't really matter in our statistics, let's just move on to the next data of interest : the sex proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      843\n",
       "female    466\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx = titanic.sex.value_counts ()\n",
    "sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      64.400306\n",
       "female    35.599694\n",
       "Name: sex, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percentages\n",
    "round(100. * sx / len(titanic.sex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 2 people out of 3 were males.\n",
    "\n",
    "If we now look at the age repartition on a plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x266d0d9da90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqAAAAHcCAYAAAAJNBjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwCgCKAAAAIwigAIAAMAoAigAAACM+n8xM2BppeUclAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x266d0d9d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic.age.hist (bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that there are more young people than old ones on the cruise. Now there might be an interesting thing to check : could we guess how many of them were on their honeymoon ?\n",
    "\n",
    "According to http://www.infoplease.com/ipa/A0005061.html, for the year 1912, we could assume that the regular groom was 25 years old, while the average lady was only 21. So all we have to do is to delete all ages outside the range [20 - 27], group people by their cabin number and count the ones that had 2 people in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B35</th>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aubart, Mme. Leontine Pauline</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17477</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>B35</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sagesser, Mlle. Emma</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17477</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>B35</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B45</th>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Snyder, Mr. John Pillsbury</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21228</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>B45</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Snyder, Mrs. John Pillsbury (Nelle Stevenson)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21228</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>B45</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C23 C25 C27</th>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winnipeg, MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winnipeg, MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C54</th>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Earnshaw, Mrs. Boulton (Olive Potter)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mt Airy, Philadelphia, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hays, Miss. Margaret Bechstein</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">E50</th>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harder, Mr. George Achilles</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11765</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>E50</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harder, Mrs. George Achilles (Dorothy Annan)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11765</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>E50</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">F33</th>\n",
       "      <th>349</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown, Miss. Amelia \"Mildred\"</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248733</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>F33</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London / Montreal, PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cook, Mrs. (Selena Rogers)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14266</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>F33</td>\n",
       "      <td>S</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pclass  survived  \\\n",
       "cabin                               \n",
       "B35         12        1         1   \n",
       "            255       1         1   \n",
       "B45         271       1         1   \n",
       "            272       1         1   \n",
       "C23 C25 C27 111       1         1   \n",
       "            113       1         1   \n",
       "C54         102       1         1   \n",
       "            153       1         1   \n",
       "E50         143       1         1   \n",
       "            144       1         1   \n",
       "F33         349       2         1   \n",
       "            380       2         1   \n",
       "\n",
       "                                                          name     sex   age  \\\n",
       "cabin                                                                          \n",
       "B35         12                   Aubart, Mme. Leontine Pauline  female  24.0   \n",
       "            255                           Sagesser, Mlle. Emma  female  24.0   \n",
       "B45         271                     Snyder, Mr. John Pillsbury    male  24.0   \n",
       "            272  Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0   \n",
       "C23 C25 C27 111                 Fortune, Miss. Alice Elizabeth  female  24.0   \n",
       "            113                     Fortune, Miss. Mabel Helen  female  23.0   \n",
       "C54         102          Earnshaw, Mrs. Boulton (Olive Potter)  female  23.0   \n",
       "            153                 Hays, Miss. Margaret Bechstein  female  24.0   \n",
       "E50         143                    Harder, Mr. George Achilles    male  25.0   \n",
       "            144   Harder, Mrs. George Achilles (Dorothy Annan)  female  25.0   \n",
       "F33         349                  Brown, Miss. Amelia \"Mildred\"  female  24.0   \n",
       "            380                     Cook, Mrs. (Selena Rogers)  female  22.0   \n",
       "\n",
       "                 sibsp  parch       ticket      fare        cabin embarked  \\\n",
       "cabin                                                                        \n",
       "B35         12       0      0     PC 17477   69.3000          B35        C   \n",
       "            255      0      0     PC 17477   69.3000          B35        C   \n",
       "B45         271      1      0        21228   82.2667          B45        S   \n",
       "            272      1      0        21228   82.2667          B45        S   \n",
       "C23 C25 C27 111      3      2        19950  263.0000  C23 C25 C27        S   \n",
       "            113      3      2        19950  263.0000  C23 C25 C27        S   \n",
       "C54         102      0      1        11767   83.1583          C54        C   \n",
       "            153      0      0        11767   83.1583          C54        C   \n",
       "E50         143      1      0        11765   55.4417          E50        C   \n",
       "            144      1      0        11765   55.4417          E50        C   \n",
       "F33         349      0      0       248733   13.0000          F33        S   \n",
       "            380      0      0  W./C. 14266   10.5000          F33        S   \n",
       "\n",
       "                boat  body                  home.dest  \n",
       "cabin                                                  \n",
       "B35         12     9   NaN              Paris, France  \n",
       "            255    9   NaN                        NaN  \n",
       "B45         271    7   NaN            Minneapolis, MN  \n",
       "            272    7   NaN            Minneapolis, MN  \n",
       "C23 C25 C27 111   10   NaN               Winnipeg, MB  \n",
       "            113   10   NaN               Winnipeg, MB  \n",
       "C54         102    7   NaN  Mt Airy, Philadelphia, PA  \n",
       "            153    7   NaN               New York, NY  \n",
       "E50         143    5   NaN               Brooklyn, NY  \n",
       "            144    5   NaN               Brooklyn, NY  \n",
       "F33         349   11   NaN      London / Montreal, PQ  \n",
       "            380   14   NaN               Pennsylvania  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top(df, column, n=5):\n",
    "    return df.sort_values(by=column, ascending=False)[:n]\n",
    "honeymoons = titanic [(titanic.age >= 20) & (titanic.age < 27)].groupby('cabin').filter (lambda x: len(x) > 1).groupby ('cabin').apply (top, column='cabin')\n",
    "honeymoons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the cabins where the two people were of the same sex (same-sex mariage was probably forbidden back then), we see that 2 couples were on their honeymoon.\n",
    "\n",
    "Now let's move on to the parents and siblings data. We could first check if there is any wrong data by making sure that the total of siblings/spouses is an even number (each sibling counts for the other one), and same for the parents/children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['sibsp'].sum ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['parch'].sum ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be an error somewhere, because the number of siblings/spouses aboard is odd. It should really be even, as every link between siblings/spouses should be counted twice, because the linked one is also registered. Is the captain registered ? Is there any husband/wife expecting divorce ? We can't really know for sure.\n",
    "\n",
    "As for the other parameters, we can forget the ticket number, as it doesn't give any details about our data (each ticket is unique). We can just state if the data is correct by checking its uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.ticket.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, an unexpected result occured. We need to go deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA. 2343              11\n",
       "1601                   8\n",
       "CA 2144                8\n",
       "3101295                7\n",
       "PC 17608               7\n",
       "S.O.C. 14879           7\n",
       "347077                 7\n",
       "347082                 7\n",
       "19950                  6\n",
       "382652                 6\n",
       "113781                 6\n",
       "347088                 6\n",
       "349909                 5\n",
       "220845                 5\n",
       "113503                 5\n",
       "PC 17757               5\n",
       "W./C. 6608             5\n",
       "4133                   5\n",
       "W./C. 6607             4\n",
       "SC/Paris 2123          4\n",
       "C.A. 34651             4\n",
       "16966                  4\n",
       "230136                 4\n",
       "LINE                   4\n",
       "PC 17760               4\n",
       "PC 17483               4\n",
       "PC 17755               4\n",
       "113760                 4\n",
       "2666                   4\n",
       "17421                  4\n",
       "                      ..\n",
       "13568                  1\n",
       "A/5. 10482             1\n",
       "PC 17754               1\n",
       "36209                  1\n",
       "113790                 1\n",
       "248726                 1\n",
       "2623                   1\n",
       "C.A. 49867             1\n",
       "347079                 1\n",
       "365235                 1\n",
       "SOTON/O.Q. 3101263     1\n",
       "334914                 1\n",
       "345769                 1\n",
       "PC 17609               1\n",
       "365222                 1\n",
       "250652                 1\n",
       "2670                   1\n",
       "27267                  1\n",
       "S.O.P. 1166            1\n",
       "STON/O 2. 3101294      1\n",
       "364856                 1\n",
       "13050                  1\n",
       "19988                  1\n",
       "383162                 1\n",
       "C.A. 31030             1\n",
       "A./5. 3235             1\n",
       "13214                  1\n",
       "348124                 1\n",
       "36866                  1\n",
       "345364                 1\n",
       "Name: ticket, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.ticket.value_counts ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clearly seems that a ticket counts for a family, or even a cabin. To check it out, we need to group by ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Colley, Mr. Edward Pomeroy</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5727</td>\n",
       "      <td>25.5875</td>\n",
       "      <td>E58</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victoria, BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11751</th>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mr. Richard Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11755</th>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11767</th>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Earnshaw, Mrs. Boulton (Olive Potter)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mt Airy, Philadelphia, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11769</th>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown, Mrs. John Murray (Caroline Lane Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belmont, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11770</th>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cornell, Mrs. Robert Clifford (Malvina Helen L...</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11770</td>\n",
       "      <td>25.7000</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11813</th>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bazzani, Miss. Albina</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11813</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>D15</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bucknell, Mrs. William Robert (Emma Eliza Ward)</td>\n",
       "      <td>female</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11813</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>D15</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11967</th>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mr. Dickinson H</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11967</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>B49</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mrs. Dickinson H (Helen Walton)</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11967</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>B49</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13050</th>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Beattie, Mr. Thomson</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13050</td>\n",
       "      <td>75.2417</td>\n",
       "      <td>C6</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winnipeg, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13508</th>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Clark, Mr. Walter Miller</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13508</td>\n",
       "      <td>136.7792</td>\n",
       "      <td>C89</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clark, Mrs. Walter Miller (Virginia McDowell)</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13508</td>\n",
       "      <td>136.7792</td>\n",
       "      <td>C89</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Birnbaum, Mr. Jakob</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13905</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Burns, Miss. Elizabeth Margaret</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16966</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>E40</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17474</th>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dick, Mr. Albert Adrian</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17474</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>B20</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calgary, AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dick, Mrs. Albert Adrian (Vera Gillespie)</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17474</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>B20</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calgary, AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cassebeer, Mrs. Henry Arthur Jr (Eleanor Genev...</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17770</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">19877</th>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barber, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19877</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cavendish, Mr. Tyrell William</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19877</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>C46</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Little Onn Hall, Staffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cavendish, Mrs. Tyrell William (Julia Florence...</td>\n",
       "      <td>female</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19877</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>C46</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Little Onn Hall, Staffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Case, Mr. Howard Brown</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19924</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ascot, Berkshire / Rochester, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19952</th>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24160</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27042</th>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27042</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>A23</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hessle, Yorks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33638</th>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dodge, Dr. Washington</td>\n",
       "      <td>male</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33638</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>A34</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101293</th>\n",
       "      <th>1248</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O 2. 3101294</th>\n",
       "      <th>1117</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Pekoniemi, Mr. Edvard</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101294</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101270</th>\n",
       "      <th>877</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ilmakangas, Miss. Ida Livija</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101270</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101271</th>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">STON/O2. 3101279</th>\n",
       "      <th>844</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Hakkarainen, Mr. Pekka Pietari</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101279</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hakkarainen, Mrs. Pekka Pietari (Elin Matilda ...</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101279</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101282</th>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101283</th>\n",
       "      <th>870</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Honkanen, Miss. Eliina</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101283</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/O2. 3101290</th>\n",
       "      <th>861</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Heininen, Miss. Wendla Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101290</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STON/OQ. 369943</th>\n",
       "      <th>1220</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Spinner, Mr. Henry John</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/OQ. 369943</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SW/PP 751</th>\n",
       "      <th>503</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mellors, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SW/PP 751</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chelsea, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14258</th>\n",
       "      <th>551</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ridsdale, Miss. Lucy</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14258</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London, England / Marietta, Ohio and Milwaukee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14260</th>\n",
       "      <th>523</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Oxenham, Mr. Percy Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14260</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pondersend, England / New Durham, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14263</th>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Coleridge, Mr. Reginald Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14263</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hartford, Huntingdonshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 14266</th>\n",
       "      <th>380</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cook, Mrs. (Selena Rogers)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14266</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>F33</td>\n",
       "      <td>S</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">W./C. 6607</th>\n",
       "      <th>900</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnston, Master. William Arthur \"Willie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnston, Mr. Andrew G</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnston, Mrs. Andrew G (Elizabeth \"Lily\" Watson)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">W./C. 6608</th>\n",
       "      <th>806</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ford, Miss. Doolina Margaret \"Daisy\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherfield, Sussex, England Essex Co, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ford, Miss. Robina Maggie \"Ruby\"</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherfield, Sussex, England Essex Co, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ford, Mr. Edward Watson</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherfield, Sussex, England Essex Co, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ford, Mr. William Neal</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherfield, Sussex, England Essex Co, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ford, Mrs. Edward (Margaret Ann Watson)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rotherfield, Sussex, England Essex Co, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W./C. 6609</th>\n",
       "      <th>852</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Harknett, Miss. Alice Phoebe</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 6609</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">W.E.P. 5734</th>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Chaffee, Mr. Herbert Fuller</td>\n",
       "      <td>male</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W.E.P. 5734</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>E31</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amenia, ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chaffee, Mrs. Herbert Fuller (Carrie Constance...</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W.E.P. 5734</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>E31</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amenia, ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W/C 14208</th>\n",
       "      <th>433</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Harris, Mr. Walter</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W/C 14208</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walthamstow, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WE/P 5735</th>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Crosby, Capt. Edward Gifford</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>B22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.0</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Crosby, Miss. Harriet R</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>B22</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pclass  survived  \\\n",
       "ticket                                     \n",
       "695               51         1         0   \n",
       "5727              75         1         0   \n",
       "11751             20         1         1   \n",
       "                  21         1         1   \n",
       "11755             99         1         1   \n",
       "11767             102        1         1   \n",
       "11769             8          1         1   \n",
       "                  42         1         1   \n",
       "11770             79         1         1   \n",
       "11813             18         1         1   \n",
       "                  43         1         1   \n",
       "11967             26         1         1   \n",
       "                  27         1         1   \n",
       "13050             19         1         0   \n",
       "13502             6          1         1   \n",
       "13508             71         1         0   \n",
       "                  72         1         1   \n",
       "13905             25         1         0   \n",
       "16966             44         1         1   \n",
       "17474             91         1         1   \n",
       "                  92         1         1   \n",
       "17770             59         1         1   \n",
       "19877             13         1         1   \n",
       "                  60         1         0   \n",
       "                  61         1         1   \n",
       "19924             58         1         0   \n",
       "19952             5          1         1   \n",
       "24160             0          1         1   \n",
       "27042             14         1         1   \n",
       "33638             93         1         1   \n",
       "...                        ...       ...   \n",
       "STON/O 2. 3101293 1248       3         0   \n",
       "STON/O 2. 3101294 1117       3         0   \n",
       "STON/O2. 3101270  877        3         0   \n",
       "STON/O2. 3101271  878        3         0   \n",
       "STON/O2. 3101279  844        3         0   \n",
       "                  845        3         1   \n",
       "STON/O2. 3101282  860        3         1   \n",
       "STON/O2. 3101283  870        3         1   \n",
       "STON/O2. 3101290  861        3         0   \n",
       "STON/OQ. 369943   1220       3         0   \n",
       "SW/PP 751         503        2         1   \n",
       "W./C. 14258       551        2         1   \n",
       "W./C. 14260       523        2         1   \n",
       "W./C. 14263       374        2         0   \n",
       "W./C. 14266       380        2         1   \n",
       "W./C. 6607        900        3         0   \n",
       "                  901        3         0   \n",
       "                  902        3         0   \n",
       "                  903        3         0   \n",
       "W./C. 6608        806        3         0   \n",
       "                  807        3         0   \n",
       "                  809        3         0   \n",
       "                  810        3         0   \n",
       "                  811        3         0   \n",
       "W./C. 6609        852        3         0   \n",
       "W.E.P. 5734       62         1         0   \n",
       "                  63         1         1   \n",
       "W/C 14208         433        2         0   \n",
       "WE/P 5735         81         1         0   \n",
       "                  82         1         1   \n",
       "\n",
       "                                                                     name  \\\n",
       "ticket                                                                      \n",
       "695               51                             Carlsson, Mr. Frans Olof   \n",
       "5727              75                           Colley, Mr. Edward Pomeroy   \n",
       "11751             20                        Beckwith, Mr. Richard Leonard   \n",
       "                  21     Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
       "11755             99    Duff Gordon, Lady. (Lucille Christiana Sutherl...   \n",
       "11767             102               Earnshaw, Mrs. Boulton (Olive Potter)   \n",
       "11769             8         Appleton, Mrs. Edward Dale (Charlotte Lamson)   \n",
       "                  42       Brown, Mrs. John Murray (Caroline Lane Lamson)   \n",
       "11770             79    Cornell, Mrs. Robert Clifford (Malvina Helen L...   \n",
       "11813             18                                Bazzani, Miss. Albina   \n",
       "                  43      Bucknell, Mrs. William Robert (Emma Eliza Ward)   \n",
       "11967             26                              Bishop, Mr. Dickinson H   \n",
       "                  27              Bishop, Mrs. Dickinson H (Helen Walton)   \n",
       "13050             19                                 Beattie, Mr. Thomson   \n",
       "13502             6                     Andrews, Miss. Kornelia Theodosia   \n",
       "13508             71                             Clark, Mr. Walter Miller   \n",
       "                  72        Clark, Mrs. Walter Miller (Virginia McDowell)   \n",
       "13905             25                                  Birnbaum, Mr. Jakob   \n",
       "16966             44                      Burns, Miss. Elizabeth Margaret   \n",
       "17474             91                              Dick, Mr. Albert Adrian   \n",
       "                  92            Dick, Mrs. Albert Adrian (Vera Gillespie)   \n",
       "17770             59    Cassebeer, Mrs. Henry Arthur Jr (Eleanor Genev...   \n",
       "19877             13                         Barber, Miss. Ellen \"Nellie\"   \n",
       "                  60                        Cavendish, Mr. Tyrell William   \n",
       "                  61    Cavendish, Mrs. Tyrell William (Julia Florence...   \n",
       "19924             58                               Case, Mr. Howard Brown   \n",
       "19952             5                                   Anderson, Mr. Harry   \n",
       "24160             0                         Allen, Miss. Elisabeth Walton   \n",
       "27042             14                 Barkworth, Mr. Algernon Henry Wilson   \n",
       "33638             93                                Dodge, Dr. Washington   \n",
       "...                                                                   ...   \n",
       "STON/O 2. 3101293 1248                                 Tikkanen, Mr. Juho   \n",
       "STON/O 2. 3101294 1117                              Pekoniemi, Mr. Edvard   \n",
       "STON/O2. 3101270  877                        Ilmakangas, Miss. Ida Livija   \n",
       "STON/O2. 3101271  878                       Ilmakangas, Miss. Pieta Sofia   \n",
       "STON/O2. 3101279  844                      Hakkarainen, Mr. Pekka Pietari   \n",
       "                  845   Hakkarainen, Mrs. Pekka Pietari (Elin Matilda ...   \n",
       "STON/O2. 3101282  860                              Heikkinen, Miss. Laina   \n",
       "STON/O2. 3101283  870                              Honkanen, Miss. Eliina   \n",
       "STON/O2. 3101290  861                        Heininen, Miss. Wendla Maria   \n",
       "STON/OQ. 369943   1220                            Spinner, Mr. Henry John   \n",
       "SW/PP 751         503                           Mellors, Mr. William John   \n",
       "W./C. 14258       551                                Ridsdale, Miss. Lucy   \n",
       "W./C. 14260       523                           Oxenham, Mr. Percy Thomas   \n",
       "W./C. 14263       374                     Coleridge, Mr. Reginald Charles   \n",
       "W./C. 14266       380                          Cook, Mrs. (Selena Rogers)   \n",
       "W./C. 6607        900           Johnston, Master. William Arthur \"Willie\"   \n",
       "                  901            Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "                  902                              Johnston, Mr. Andrew G   \n",
       "                  903   Johnston, Mrs. Andrew G (Elizabeth \"Lily\" Watson)   \n",
       "W./C. 6608        806                Ford, Miss. Doolina Margaret \"Daisy\"   \n",
       "                  807                    Ford, Miss. Robina Maggie \"Ruby\"   \n",
       "                  809                             Ford, Mr. Edward Watson   \n",
       "                  810                              Ford, Mr. William Neal   \n",
       "                  811             Ford, Mrs. Edward (Margaret Ann Watson)   \n",
       "W./C. 6609        852                        Harknett, Miss. Alice Phoebe   \n",
       "W.E.P. 5734       62                          Chaffee, Mr. Herbert Fuller   \n",
       "                  63    Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
       "W/C 14208         433                                  Harris, Mr. Walter   \n",
       "WE/P 5735         81                         Crosby, Capt. Edward Gifford   \n",
       "                  82                              Crosby, Miss. Harriet R   \n",
       "\n",
       "                           sex   age  sibsp  parch             ticket  \\\n",
       "ticket                                                                  \n",
       "695               51      male  33.0      0      0                695   \n",
       "5727              75      male  47.0      0      0               5727   \n",
       "11751             20      male  37.0      1      1              11751   \n",
       "                  21    female  47.0      1      1              11751   \n",
       "11755             99    female  48.0      1      0              11755   \n",
       "11767             102   female  23.0      0      1              11767   \n",
       "11769             8     female  53.0      2      0              11769   \n",
       "                  42    female  59.0      2      0              11769   \n",
       "11770             79    female  55.0      2      0              11770   \n",
       "11813             18    female  32.0      0      0              11813   \n",
       "                  43    female  60.0      0      0              11813   \n",
       "11967             26      male  25.0      1      0              11967   \n",
       "                  27    female  19.0      1      0              11967   \n",
       "13050             19      male  36.0      0      0              13050   \n",
       "13502             6     female  63.0      1      0              13502   \n",
       "13508             71      male  27.0      1      0              13508   \n",
       "                  72    female  26.0      1      0              13508   \n",
       "13905             25      male  25.0      0      0              13905   \n",
       "16966             44    female  41.0      0      0              16966   \n",
       "17474             91      male  31.0      1      0              17474   \n",
       "                  92    female  17.0      1      0              17474   \n",
       "17770             59    female   NaN      0      0              17770   \n",
       "19877             13    female  26.0      0      0              19877   \n",
       "                  60      male  36.0      1      0              19877   \n",
       "                  61    female  76.0      1      0              19877   \n",
       "19924             58      male  49.0      0      0              19924   \n",
       "19952             5       male  48.0      0      0              19952   \n",
       "24160             0     female  29.0      0      0              24160   \n",
       "27042             14      male  80.0      0      0              27042   \n",
       "33638             93      male  53.0      1      1              33638   \n",
       "...                        ...   ...    ...    ...                ...   \n",
       "STON/O 2. 3101293 1248    male  32.0      0      0  STON/O 2. 3101293   \n",
       "STON/O 2. 3101294 1117    male  21.0      0      0  STON/O 2. 3101294   \n",
       "STON/O2. 3101270  877   female  27.0      1      0   STON/O2. 3101270   \n",
       "STON/O2. 3101271  878   female  25.0      1      0   STON/O2. 3101271   \n",
       "STON/O2. 3101279  844     male  28.0      1      0   STON/O2. 3101279   \n",
       "                  845   female  24.0      1      0   STON/O2. 3101279   \n",
       "STON/O2. 3101282  860   female  26.0      0      0   STON/O2. 3101282   \n",
       "STON/O2. 3101283  870   female  27.0      0      0   STON/O2. 3101283   \n",
       "STON/O2. 3101290  861   female  23.0      0      0   STON/O2. 3101290   \n",
       "STON/OQ. 369943   1220    male  32.0      0      0    STON/OQ. 369943   \n",
       "SW/PP 751         503     male  19.0      0      0          SW/PP 751   \n",
       "W./C. 14258       551   female  50.0      0      0        W./C. 14258   \n",
       "W./C. 14260       523     male  22.0      0      0        W./C. 14260   \n",
       "W./C. 14263       374     male  29.0      0      0        W./C. 14263   \n",
       "W./C. 14266       380   female  22.0      0      0        W./C. 14266   \n",
       "W./C. 6607        900     male   NaN      1      2         W./C. 6607   \n",
       "                  901   female   NaN      1      2         W./C. 6607   \n",
       "                  902     male   NaN      1      2         W./C. 6607   \n",
       "                  903   female   NaN      1      2         W./C. 6607   \n",
       "W./C. 6608        806   female  21.0      2      2         W./C. 6608   \n",
       "                  807   female   9.0      2      2         W./C. 6608   \n",
       "                  809     male  18.0      2      2         W./C. 6608   \n",
       "                  810     male  16.0      1      3         W./C. 6608   \n",
       "                  811   female  48.0      1      3         W./C. 6608   \n",
       "W./C. 6609        852   female   NaN      0      0         W./C. 6609   \n",
       "W.E.P. 5734       62      male  46.0      1      0        W.E.P. 5734   \n",
       "                  63    female  47.0      1      0        W.E.P. 5734   \n",
       "W/C 14208         433     male  30.0      0      0          W/C 14208   \n",
       "WE/P 5735         81      male  70.0      1      1          WE/P 5735   \n",
       "                  82    female  36.0      0      2          WE/P 5735   \n",
       "\n",
       "                            fare        cabin embarked boat   body  \\\n",
       "ticket                                                               \n",
       "695               51      5.0000  B51 B53 B55        S  NaN    NaN   \n",
       "5727              75     25.5875          E58        S  NaN    NaN   \n",
       "11751             20     52.5542          D35        S    5    NaN   \n",
       "                  21     52.5542          D35        S    5    NaN   \n",
       "11755             99     39.6000          A16        C    1    NaN   \n",
       "11767             102    83.1583          C54        C    7    NaN   \n",
       "11769             8      51.4792         C101        S    D    NaN   \n",
       "                  42     51.4792         C101        S    D    NaN   \n",
       "11770             79     25.7000         C101        S    2    NaN   \n",
       "11813             18     76.2917          D15        C    8    NaN   \n",
       "                  43     76.2917          D15        C    8    NaN   \n",
       "11967             26     91.0792          B49        C    7    NaN   \n",
       "                  27     91.0792          B49        C    7    NaN   \n",
       "13050             19     75.2417           C6        C    A    NaN   \n",
       "13502             6      77.9583           D7        S   10    NaN   \n",
       "13508             71    136.7792          C89        C  NaN    NaN   \n",
       "                  72    136.7792          C89        C    4    NaN   \n",
       "13905             25     26.0000          NaN        C  NaN  148.0   \n",
       "16966             44    134.5000          E40        C    3    NaN   \n",
       "17474             91     57.0000          B20        S    3    NaN   \n",
       "                  92     57.0000          B20        S    3    NaN   \n",
       "17770             59     27.7208          NaN        C    5    NaN   \n",
       "19877             13     78.8500          NaN        S    6    NaN   \n",
       "                  60     78.8500          C46        S  NaN  172.0   \n",
       "                  61     78.8500          C46        S    6    NaN   \n",
       "19924             58     26.0000          NaN        S  NaN    NaN   \n",
       "19952             5      26.5500          E12        S    3    NaN   \n",
       "24160             0     211.3375           B5        S    2    NaN   \n",
       "27042             14     30.0000          A23        S    B    NaN   \n",
       "33638             93     81.8583          A34        S   13    NaN   \n",
       "...                          ...          ...      ...  ...    ...   \n",
       "STON/O 2. 3101293 1248    7.9250          NaN        S  NaN    NaN   \n",
       "STON/O 2. 3101294 1117    7.9250          NaN        S  NaN    NaN   \n",
       "STON/O2. 3101270  877     7.9250          NaN        S  NaN    NaN   \n",
       "STON/O2. 3101271  878     7.9250          NaN        S  NaN    NaN   \n",
       "STON/O2. 3101279  844    15.8500          NaN        S  NaN    NaN   \n",
       "                  845    15.8500          NaN        S   15    NaN   \n",
       "STON/O2. 3101282  860     7.9250          NaN        S  NaN    NaN   \n",
       "STON/O2. 3101283  870     7.9250          NaN        S  NaN    NaN   \n",
       "STON/O2. 3101290  861     7.9250          NaN        S  NaN    NaN   \n",
       "STON/OQ. 369943   1220    8.0500          NaN        S  NaN    NaN   \n",
       "SW/PP 751         503    10.5000          NaN        S    B    NaN   \n",
       "W./C. 14258       551    10.5000          NaN        S   13    NaN   \n",
       "W./C. 14260       523    10.5000          NaN        S   13    NaN   \n",
       "W./C. 14263       374    10.5000          NaN        S  NaN    NaN   \n",
       "W./C. 14266       380    10.5000          F33        S   14    NaN   \n",
       "W./C. 6607        900    23.4500          NaN        S  NaN    NaN   \n",
       "                  901    23.4500          NaN        S  NaN    NaN   \n",
       "                  902    23.4500          NaN        S  NaN    NaN   \n",
       "                  903    23.4500          NaN        S  NaN    NaN   \n",
       "W./C. 6608        806    34.3750          NaN        S  NaN    NaN   \n",
       "                  807    34.3750          NaN        S  NaN    NaN   \n",
       "                  809    34.3750          NaN        S  NaN    NaN   \n",
       "                  810    34.3750          NaN        S  NaN    NaN   \n",
       "                  811    34.3750          NaN        S  NaN    NaN   \n",
       "W./C. 6609        852     7.5500          NaN        S  NaN    NaN   \n",
       "W.E.P. 5734       62     61.1750          E31        S  NaN    NaN   \n",
       "                  63     61.1750          E31        S    4    NaN   \n",
       "W/C 14208         433    10.5000          NaN        S  NaN    NaN   \n",
       "WE/P 5735         81     71.0000          B22        S  NaN  269.0   \n",
       "                  82     71.0000          B22        S    7    NaN   \n",
       "\n",
       "                                                                home.dest  \n",
       "ticket                                                                     \n",
       "695               51                                         New York, NY  \n",
       "5727              75                                         Victoria, BC  \n",
       "11751             20                                         New York, NY  \n",
       "                  21                                         New York, NY  \n",
       "11755             99                                       London / Paris  \n",
       "11767             102                           Mt Airy, Philadelphia, PA  \n",
       "11769             8                                   Bayside, Queens, NY  \n",
       "                  42                                          Belmont, MA  \n",
       "11770             79                                         New York, NY  \n",
       "11813             18                                                  NaN  \n",
       "                  43                                     Philadelphia, PA  \n",
       "11967             26                                         Dowagiac, MI  \n",
       "                  27                                         Dowagiac, MI  \n",
       "13050             19                                         Winnipeg, MN  \n",
       "13502             6                                            Hudson, NY  \n",
       "13508             71                                      Los Angeles, CA  \n",
       "                  72                                      Los Angeles, CA  \n",
       "13905             25                                    San Francisco, CA  \n",
       "16966             44                                                  NaN  \n",
       "17474             91                                          Calgary, AB  \n",
       "                  92                                          Calgary, AB  \n",
       "17770             59                                         New York, NY  \n",
       "19877             13                                                  NaN  \n",
       "                  60                              Little Onn Hall, Staffs  \n",
       "                  61                              Little Onn Hall, Staffs  \n",
       "19924             58                     Ascot, Berkshire / Rochester, NY  \n",
       "19952             5                                          New York, NY  \n",
       "24160             0                                          St Louis, MO  \n",
       "27042             14                                        Hessle, Yorks  \n",
       "33638             93                                    San Francisco, CA  \n",
       "...                                                                   ...  \n",
       "STON/O 2. 3101293 1248                                                NaN  \n",
       "STON/O 2. 3101294 1117                                                NaN  \n",
       "STON/O2. 3101270  877                                                 NaN  \n",
       "STON/O2. 3101271  878                                                 NaN  \n",
       "STON/O2. 3101279  844                                                 NaN  \n",
       "                  845                                                 NaN  \n",
       "STON/O2. 3101282  860                                                 NaN  \n",
       "STON/O2. 3101283  870                                                 NaN  \n",
       "STON/O2. 3101290  861                                                 NaN  \n",
       "STON/OQ. 369943   1220                                                NaN  \n",
       "SW/PP 751         503                                     Chelsea, London  \n",
       "W./C. 14258       551   London, England / Marietta, Ohio and Milwaukee...  \n",
       "W./C. 14260       523                Pondersend, England / New Durham, NJ  \n",
       "W./C. 14263       374                           Hartford, Huntingdonshire  \n",
       "W./C. 14266       380                                        Pennsylvania  \n",
       "W./C. 6607        900                                                 NaN  \n",
       "                  901                                                 NaN  \n",
       "                  902                                                 NaN  \n",
       "                  903                                                 NaN  \n",
       "W./C. 6608        806           Rotherfield, Sussex, England Essex Co, MA  \n",
       "                  807           Rotherfield, Sussex, England Essex Co, MA  \n",
       "                  809           Rotherfield, Sussex, England Essex Co, MA  \n",
       "                  810           Rotherfield, Sussex, England Essex Co, MA  \n",
       "                  811           Rotherfield, Sussex, England Essex Co, MA  \n",
       "W./C. 6609        852                                                 NaN  \n",
       "W.E.P. 5734       62                                           Amenia, ND  \n",
       "                  63                                           Amenia, ND  \n",
       "W/C 14208         433                                Walthamstow, England  \n",
       "WE/P 5735         81                                        Milwaukee, WI  \n",
       "                  82                                        Milwaukee, WI  \n",
       "\n",
       "[1283 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby ('ticket').apply(top, column='ticket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems logical actually. So we can assume that one ticket counts for a family.\n",
    "\n",
    "Next question is : how much money do you have to spend to cruise on the titanic ? It could be interesting to group by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass\n",
       "1    87.508992\n",
       "2    21.179196\n",
       "3    13.302889\n",
       "Name: fare, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(titanic.pclass) ['fare'].mean ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a huge difference over 1st and 2nd class over here. According to https://www.measuringworth.com/m/calculators/ukcompare/, today it would be equivalent to 7,768.00 Â£ for the first class, against 1,161.00 Â£ for the third class. Quite expensive.\n",
    "\n",
    "The last data we could be interested in is the embarquement location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.embarked.value_counts ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to wikipedia, this matches the timeline. The Titanic went from Southampton to Queenstown through Cherbourg.\n",
    "\n",
    "That's all for the intersting data we gathered through the excel file. Now time to focus on more specific things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "To calculate the survival rate of both male and female people, we need to group the whole data frame by sex, and then do a simple survive/die rate on each one of them (using the mean, as survival/death is a simple bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    0.727468\n",
       "male      0.190985\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby ('sex').mean () ['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that about 72% of the women survived, against only 19% for the men. So the \"women first\" thing was actually not a lie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "This time we need to include the class property in our group by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex     pclass\n",
       "female  1         0.965278\n",
       "        2         0.886792\n",
       "        3         0.490741\n",
       "male    1         0.340782\n",
       "        2         0.146199\n",
       "        3         0.152130\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby (['sex', 'pclass']).mean () ['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the ladies from first class survived, when only half of them from third class did ! And it's the same for men, with a much lower rate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "To add the age category, we need to use the pandas function 'cut' as a new entry for our titanic data frame. Then just apply the mean just as what we've done in the last 2 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_category  pclass  sex   \n",
       "child         1       female    0.500000\n",
       "                      male      1.000000\n",
       "              2       female    1.000000\n",
       "                      male      0.916667\n",
       "              3       female    0.484848\n",
       "                      male      0.325000\n",
       "adolescent    1       female    1.000000\n",
       "                      male      0.285714\n",
       "              2       female    0.928571\n",
       "                      male      0.090909\n",
       "              3       female    0.500000\n",
       "                      male      0.129412\n",
       "adult         1       female    0.964602\n",
       "                      male      0.335821\n",
       "              2       female    0.864865\n",
       "                      male      0.081967\n",
       "              3       female    0.456790\n",
       "                      male      0.157658\n",
       "senior        1       female    1.000000\n",
       "                      male      0.200000\n",
       "              2       female         NaN\n",
       "                      male      0.000000\n",
       "              3       female         NaN\n",
       "                      male      0.000000\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['age_category'] = pd.cut(titanic.age, [0,14,21,65,80], labels=['child','adolescent','adult','senior'])\n",
    "titanic.groupby (['age_category', 'pclass', 'sex']).mean() ['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we did indeed see the results of the \"women first\" policy in questions 2 and 3, we cannot unfortunately conclude from this data that a \"children first\" policy was either applied or was effective. The rates are almost higher for the adult category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) Wes McKinney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
