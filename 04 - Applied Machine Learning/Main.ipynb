{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and simple cleaning of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, some simple cleaning. We remove features that have nothing to do with the skin color. We remove player (we will use 'playerShort' later for aggregating), birthday, Alpha_3 (since it is the same as refCountry) and photoID.\n",
    "\n",
    "There are missing values for height, weight and position. And also 163 dyads miss the information for the implicit association test and the explicit bias scores.\n",
    "\n",
    "First we will remove the refrees that got in the data by mistake (as mentioned in the preprocessing article) and see if the problem is solved then. After removing these refrees, there were still 110 samples with missing data which we just removed.\n",
    "\n",
    "The missing values of height and weight are replaced by the respective means and the missing values in position are replaced by the most frequently occuring position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv ('CrowdstormingDataJuly1st.csv')\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove values without skin color rating (we know all samples have either two raters or none)\n",
    "df_train_raw = df [pd.notnull (df ['rater1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "df_train_raw = df_train_raw.drop(['birthday', 'player', 'Alpha_3', 'photoID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove referees that are not supposed to be in here\n",
    "refrees_to_remove = df_train_raw.groupby('refNum').sum()[df_train_raw.groupby('refNum').sum()['games'] < 22].index.tolist()\n",
    "df_train_raw = df_train_raw[~df_train_raw.refNum.isin(refrees_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove samples that don't have IAT or Exp score information\n",
    "df_train_raw = df_train_raw[df_train_raw.meanIAT.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set missing height, weight and position values to mean\n",
    "mean_height = df_train_raw.height.mean()\n",
    "mean_weight = df_train_raw.weight.mean()\n",
    "most_frequent_position = df_train_raw['position'].value_counts().index[0]\n",
    "\n",
    "df_train_raw.loc[df_train_raw.height.isnull(),'height'] = mean_height\n",
    "df_train_raw.loc[df_train_raw.weight.isnull(),'weight'] = mean_weight\n",
    "df_train_raw['position'] = df_train_raw['position'].fillna(most_frequent_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new feature called \"skinColor\" which is the average of both ratings, then mapped to either \"white\" or \"black\" to simplify our classification.\n",
    "\n",
    "Position, club and leagueCountry are not numerical, we use dummy variables to make them numerical. For now we left out the club feature because it would cause a lot of dummy variables and we assume it is not a significant feature. We will check in the end if we get significantly better result if we add this feature.\n",
    "\n",
    "We drop height and weight, as there are not features that we are looking for to influence the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_train_raw\n",
    "\n",
    "# create feature \"skinColor\"\n",
    "def attribute_skin_label(val):\n",
    "    if val > 0.5:\n",
    "        return 1 #  \"black\"\n",
    "    else:\n",
    "        return 0  # \"white\"\n",
    "    \n",
    "#Replace rating with either white or black\n",
    "df_train['skinColor'] = df_train[['rater1','rater2']].mean(axis=1).apply(attribute_skin_label)\n",
    "df_train = df_train.drop(['rater1', 'rater2'], 1)\n",
    "\n",
    "# add dummy variables for position, club and leagueCountry\n",
    "n_positions = len(df_train.position.unique())\n",
    "#n_club = len(df_train.club.unique())\n",
    "n_leagueCountry = len(df_train.leagueCountry.unique())\n",
    "\n",
    "d_positions = pd.get_dummies(df_train['position'])\n",
    "#d_club = pd.get_dummies(df_train['club'])\n",
    "d_leagueCountry = pd.get_dummies(df_train['leagueCountry'])\n",
    "\n",
    "df_train = pd.concat([df_train, d_positions, d_leagueCountry], axis=1)\n",
    "df_train = df_train.drop(['position', 'club', 'leagueCountry','height','weight'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking how many \"white\" and \"black\" players we have\n",
    "df_train['skinColor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player aggregation and feature engineering\n",
    "We added 6 new features: the meanIAT and the meanExp per dyad are multiplied with each of the values 'redCards', 'YellowCards', and 'YellowRedCards'. We do this because the average of the meanIAT or meanExp per player is not useful. This average only tells yo something about the racial bias of the countries this player has been refereed by. The most important is the influence of these referees on the number of cards he got. So the combined features.\n",
    "\n",
    "We aggregate per player because we want to predict the skin color of a given player, not of a given dyad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['IATRedCards'] = df_train['redCards']*df_train['meanIAT']\n",
    "df_train['ExpRedCards'] = df_train['redCards']*df_train['meanExp']\n",
    "df_train['IATYellowRedCards'] = df_train['yellowReds']*df_train['meanIAT']\n",
    "df_train['ExpYellowRedCards'] = df_train['yellowReds']*df_train['meanExp']\n",
    "df_train['IATYellowCards'] = df_train['yellowCards']*df_train['meanIAT']\n",
    "df_train['ExpYellowCards'] = df_train['yellowCards']*df_train['meanExp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_agg = df_train.groupby('playerShort').sum().columns\n",
    "summed = df_train[['playerShort','games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards']].groupby('playerShort').sum()\n",
    "meaned = df_train[['playerShort', 'skinColor','Attacking Midfielder', 'Center Back', 'Center Forward',\n",
    "       'Center Midfielder', 'Defensive Midfielder', 'Goalkeeper',\n",
    "       'Left Fullback', 'Left Midfielder', 'Left Winger', 'Right Fullback',\n",
    "       'Right Midfielder', 'Right Winger', 'England', 'France', 'Germany',\n",
    "       'Spain', 'meanIAT', 'meanExp', 'IATRedCards', 'ExpRedCards', 'IATYellowRedCards', 'ExpYellowRedCards', 'IATYellowCards', 'ExpYellowCards' ]].groupby('playerShort').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg = pd.concat([summed, meaned], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the model\n",
    "\n",
    "\n",
    "We decide to keep meanIAT and meanExp. As we have aggregated by player, the represent the average amount of bias the players receive over all the referees they meet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Baseline model, only based on cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "Y = np.asarray(df_agg['skinColor'], dtype='str')\n",
    "X = df_agg[['yellowCards','yellowReds', 'redCards']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns  # Just checking the columns we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(clf, X, Y, cv=5, scoring='accuracy'))\n",
    "clf.fit(X,Y)\n",
    "feature_importance(X, clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (RandomForestClassifier) - Model 1\"\n",
    "\n",
    "plot_learning_curve(title, clf, X, Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Model with all raw data that came out of preprocessing (no combined features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "Y = np.asarray(df_agg['skinColor'], dtype='str')\n",
    "X = df_agg.drop(['skinColor','IATRedCards','ExpRedCards', 'IATYellowRedCards', 'ExpYellowRedCards','IATYellowCards', 'ExpYellowCards' ], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns  # Just checking the columns we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(clf, X, Y, cv=5, scoring='accuracy'))\n",
    "clf.fit(X,Y)\n",
    "feature_importance(X, clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (RandomForestClassifier) - Model 2\"\n",
    "\n",
    "plot_learning_curve(title, clf, X, Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Model with added features that multiply the meanIAT and the meanExp with the red/yellow/yellowred cards values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "Y = np.asarray(df_agg['skinColor'], dtype='str')\n",
    "X = df_agg.drop(['skinColor'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns  # Just checking the columns we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(clf, X, Y, cv=5, scoring='accuracy'))\n",
    "clf.fit(X,Y)\n",
    "feature_importance(X, clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (RandomForestClassifier) - Model 3\"\n",
    "\n",
    "plot_learning_curve(title, clf, X, Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_importance(X, features):\n",
    "    feature_importance = {}\n",
    "    for x,y in zip(X.columns,features):\n",
    "        feature_importance[x]=y\n",
    "    import operator\n",
    "    sorted_feature_importance = sorted(feature_importance.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    for i in range(min(len(features),5)):\n",
    "        print (sorted_feature_importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(title, estimator, X, y, cv=20):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "        \n",
    "    estimator: clf\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: nothing dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_agg.drop(['skinColor'], 1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++').fit(X)\n",
    "mixed_perc = abs(df_agg['skinColor'] - kmeans.labels_).sum()/df_agg.shape[0]\n",
    "print(\"mixed percentage: \", mixed_perc)\n",
    "print(\"silhouette score: \", silhouette_score(X, kmeans.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: everything dropped, except for the cards and the IAT and Exp scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_agg.drop(['skinColor', 'games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'Attacking Midfielder', 'Center Back',\n",
    "       'Center Forward', 'Center Midfielder', 'Defensive Midfielder',\n",
    "       'Goalkeeper', 'Left Fullback', 'Left Midfielder', 'Left Winger',\n",
    "       'Right Fullback', 'Right Midfielder', 'Right Winger', 'England',\n",
    "       'France', 'Germany', 'Spain'], 1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++').fit(X)\n",
    "mixed_perc = abs(df_agg['skinColor'] - kmeans.labels_).sum()/df_agg.shape[0]\n",
    "print(\"mixed percentage: \", mixed_perc)\n",
    "print(\"silhouette score: \", silhouette_score(X, kmeans.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: everything dropped, except for the combined IAT/Exp + cards scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_agg.drop(['skinColor','games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards',\n",
    "       'yellowReds', 'redCards', 'Attacking Midfielder', 'Center Back',\n",
    "       'Center Forward', 'Center Midfielder', 'Defensive Midfielder',\n",
    "       'Goalkeeper', 'Left Fullback', 'Left Midfielder', 'Left Winger',\n",
    "       'Right Fullback', 'Right Midfielder', 'Right Winger', 'England',\n",
    "       'France', 'Germany', 'Spain', 'meanIAT', 'meanExp'], 1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++').fit(X)\n",
    "mixed_perc = abs(df_agg['skinColor'] - kmeans.labels_).sum()/df_agg.shape[0]\n",
    "print(\"mixed percentage: \", mixed_perc)\n",
    "print(\"silhouette score: \", silhouette_score(X, kmeans.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: cluster by position (defense/attacker?), keeping goals and the cards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_agg.drop(['skinColor','games', 'victories', 'ties', 'defeats', 'Attacking Midfielder', 'Center Back',\n",
    "       'Center Forward', 'Center Midfielder', 'Defensive Midfielder',\n",
    "       'Goalkeeper', 'Left Fullback', 'Left Midfielder', 'Left Winger',\n",
    "       'Right Fullback', 'Right Midfielder', 'Right Winger', 'England',\n",
    "       'France', 'Germany', 'Spain', 'meanIAT', 'meanExp', 'IATRedCards',\n",
    "       'ExpRedCards', 'IATYellowRedCards', 'ExpYellowRedCards',\n",
    "       'IATYellowCards', 'ExpYellowCards'], 1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++').fit(X)\n",
    "mixed_perc = abs(df_agg['skinColor'] - kmeans.labels_).sum()/df_agg.shape[0]\n",
    "print(\"mixed percentage: \", mixed_perc)\n",
    "print(\"silhouette score: \", silhouette_score(X, kmeans.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
